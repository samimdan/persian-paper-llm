{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "863a6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from docx import Document\n",
    "doc=Document('thesis1.docx')\n",
    "text=\" \".join([p.text for p in doc.paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78af307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\u0600-\\u06FF\\s]\", \"\", text)  \n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "cleaned_text = clean_text(text)\n",
    "sentences = cleaned_text.split(\".\") \n",
    "words = cleaned_text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cfdac1",
   "metadata": {},
   "source": [
    "preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "X = []\n",
    "y = []\n",
    "for i in range(window_size, len(words)):\n",
    "    X.append(words[i-window_size:i])\n",
    "    y.append(words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aaae6d",
   "metadata": {},
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f339be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "counter = Counter(words)\n",
    "vocab = [\"<pad>\", \"<unk>\"] + list(counter.keys())\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "X_idx = [\n",
    "    [word2idx.get(w, word2idx[\"<unk>\"]) for w in seq]\n",
    "    for seq in X\n",
    "]\n",
    "\n",
    "y_idx = [word2idx.get(w, word2idx[\"<unk>\"]) for w in y]\n",
    "\n",
    "X = torch.tensor(X_idx)\n",
    "y = torch.tensor(y_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73418b",
   "metadata": {},
   "source": [
    "convert each word to unique number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4afba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9fc03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91b3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d681d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65db73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_62152\\2279556815.py:2: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  fasttext_model = FastText.load_fasttext_format('cc.fa.300.bin')\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "fasttext_model = FastText.load_fasttext_format('cc.fa.300.bin')\n",
    "embed_dim = 300\n",
    "embedding_matrix = torch.zeros((vocab_size, embed_dim))\n",
    "for word, idx in word2idx.items():\n",
    "  if word in fasttext_model.wv:\n",
    "    embedding_matrix[idx] = torch.tensor(fasttext_model.wv[word])\n",
    "    embedding_matrix=embedding_matrix.cuda()\n",
    "  else:\n",
    "    embedding_matrix[idx] = torch.randn(embed_dim)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92ffaec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn as nn\n",
    "embedding_layer=nn.Embedding.from_pretrained(embedding_matrix,freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2702578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NextWordBiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, vocab_size,dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(embedding_matrix, dtype=torch.float32),\n",
    "            freeze=True \n",
    "        )\n",
    "\n",
    "        # مقدار embedding_dim رو از nn.Embedding بدست میاریم\n",
    "        embedding_dim = self.embedding.embedding_dim\n",
    "\n",
    "    \n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "            \n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "     \n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # (B, T, embedding_dim)\n",
    "        out, _ = self.bilstm(x)  # (B, T, 2*hidden_dim)\n",
    "        out = out[:, -1, :]  \n",
    "        out = self.fc(out)  # (B, vocab_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c84fcfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 4.2268, Val Loss: 6.0741\n",
      "Epoch 11, Train Loss: 6.7748, Val Loss: 6.0741\n",
      "Early stopping at epoch 16\n"
     ]
    }
   ],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=15, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# In training loop\n",
    "early_stopping = EarlyStopping(patience=15)\n",
    "\n",
    "for epoch in range(300):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # ... training code ...\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce1159e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b047974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_62152\\2833679165.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(embedding_matrix, dtype=torch.float32),\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m NextWordBiLSTM(\n\u001b[0;32m     15\u001b[0m     embedding_matrix,\n\u001b[0;32m     16\u001b[0m     hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m     17\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39mvocab_size\n\u001b[0;32m     18\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m, in \u001b[0;36mNextWordBiLSTM.__init__\u001b[1;34m(self, embedding_matrix, hidden_dim, vocab_size)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# مقدار embedding_dim رو از nn.Embedding بدست میاریم\u001b[39;00m\n\u001b[0;32m     15\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39membedding_dim\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbilstm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLSTM(\n\u001b[0;32m     19\u001b[0m     input_size\u001b[38;5;241m=\u001b[39membedding_dim,\n\u001b[0;32m     20\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39mhidden_dim,\n\u001b[0;32m     21\u001b[0m     batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m     bidirectional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m     dropout\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[0;32m     24\u001b[0m     \n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(torch\u001b[38;5;241m.\u001b[39mdropout)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(torch\u001b[38;5;241m.\u001b[39mdropout)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:977\u001b[0m, in \u001b[0;36mLSTM.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 977\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:106\u001b[0m, in \u001b[0;36mRNNBase.__init__\u001b[1;34m(self, mode, input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional, proj_size, device, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m bias\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;241m=\u001b[39m batch_first\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(dropout)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional \u001b[38;5;241m=\u001b[39m bidirectional\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_size \u001b[38;5;241m=\u001b[39m proj_size\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X.cpu(), y.cpu(), test_size=0.2, random_state=42\n",
    ")\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "model = NextWordBiLSTM(\n",
    "    embedding_matrix,\n",
    "    hidden_dim=128,\n",
    "    vocab_size=vocab_size\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c18b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "def sample_top_k(output, top_k=5, temperature=0.8):\n",
    "\n",
    "    logits = output.squeeze() / temperature\n",
    "    probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
    "    \n",
    "\n",
    "    top_indices = probs.argsort()[-top_k:]\n",
    "    top_probs = probs[top_indices]\n",
    "    top_probs = top_probs / top_probs.sum()  # نرمال‌سازی\n",
    "    chosen_idx = np.random.choice(top_indices, p=top_probs)\n",
    "    \n",
    "    return chosen_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "241a32fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Loss: 6.0726\n",
      "\n",
      "Seed: تحلیل و شناسایی الگوهای\n",
      "Generated: تحلیل و شناسایی الگوهای پویا و در این حوزه و سپس تحلیل و روشهای پویا در تشخیص احساسات در این حوزه از کلاسهای و تحلیل و برای تشخیص احساسات در طول زمان و دقت\n",
      "\n",
      "Final Validation Loss: 6.0726\n",
      "\n",
      "Seed: در این پژوهش به\n",
      "Generated: در این پژوهش به بررسی داده است که مدل با دقت در طول زمان به خوبی در طول زمان و تعداد اپوک و شناسایی و پیشبینی و شناسایی دادههای پویا را فراهم\n",
      "\n",
      "Final Validation Loss: 6.0726\n",
      "\n",
      "Seed: روش تحقیق این\n",
      "Generated: روش تحقیق این فصل تحقیقات و در این حوزه و سپس به دلیل سادگی برای در طول زمان است در طول زمان آموزش و دقت مدل در طول زمان است که\n",
      "\n",
      "روش تحقیق این فصل تحقیقات و در این حوزه و سپس به دلیل سادگی برای در طول زمان است در طول زمان آموزش و دقت مدل در طول زمان است که\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, seed_text, next_words=50, seq_length=10,\n",
    "                  top_k=5, temperature=0.8, device='cuda'):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      val_outputs = model(X_val)\n",
    "      val_loss = criterion(val_outputs, y_val)\n",
    "      print(f\"Final Validation Loss: {val_loss.item():.4f}\")\n",
    "    words = seed_text.split()\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        # استفاده از آخرین seq_length کلمه\n",
    "        input_seq = [word2idx.get(w, word2idx[\"<unk>\"]) for w in words[-seq_length:]]\n",
    "        \n",
    "        # اگر seed کوتاه بود، با <pad> پر می‌کنیم\n",
    "        if len(input_seq) < seq_length:\n",
    "            input_seq = [word2idx[\"<pad>\"]] * (seq_length - len(input_seq)) + input_seq\n",
    "        \n",
    "        input_seq = torch.tensor(input_seq).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq)\n",
    "            predicted_idx = sample_top_k(output, top_k=top_k, temperature=temperature)\n",
    "            predicted_word = idx2word.get(predicted_idx, \"<unk>\")\n",
    "\n",
    "        if len(words) > 1 and predicted_word == words[-1]:\n",
    "            continue  \n",
    "        \n",
    "        words.append(predicted_word)\n",
    "    \n",
    "    # ✅ Return the generated text\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "\n",
    "seeds = [\n",
    "    \"تحلیل و شناسایی الگوهای\",\n",
    "    \"در این پژوهش به\",\n",
    "    \"روش تحقیق این\"\n",
    "]\n",
    "\n",
    "for seed in seeds:\n",
    "    text = generate_text(model, seed_text=seed, next_words=30, \n",
    "                         seq_length=5, top_k=5, temperature=0.8, device=device)\n",
    "    print(f\"\\nSeed: {seed}\")\n",
    "    print(f\"Generated: {text}\\n\")\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
